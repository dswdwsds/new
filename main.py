import cloudscraper
from bs4 import BeautifulSoup
import time
import json
import re
from datetime import datetime
import os
import base64
import requests
# ØªØ£ÙƒØ¯ Ø£Ù† 'notifier' Ù…ØªØ§Ø­ ÙÙŠ Ø¨ÙŠØ¦Ø© GitHub Actions Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ
# Ù…Ù† Ø§Ù„Ù…ÙØªØ±Ø¶ Ø£Ù†Ùƒ Ù‚Ù…Øª Ø¨ØªØ¶Ù…ÙŠÙ† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ send_discord_notification ÙÙŠ Ù…Ù„Ù notifier.py
from notifier import send_discord_notification

# Ø¥Ø¹Ø¯Ø§Ø¯ GitHub Ùˆ Discord
access_token = os.getenv("ACCESS_TOKEN")

repo_name = "abdo12249/1"
remote_folder = "test1/episodes"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ù„Ù„Ø£Ù†Ù…ÙŠØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
repo_name_log = "abdo12249/test" # ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
missing_anime_log_filename = "missing_anime_log.json"

BASE_URL = "https://4i.nxdwle.shop"
EPISODE_LIST_URL = BASE_URL + "/episode/"
HEADERS = {"User-Agent": "Mozilla/5.0"}

scraper = cloudscraper.create_scraper()

def to_id_format(text):
    text = text.strip().lower()
    text = text.replace(":", "")
    # ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø§Ù„Ø¹Ø§Ø¯ÙŠ: ØªÙ… Ù†Ù‚Ù„ Ø§Ù„ÙˆØ§ØµÙ„Ø© Ø¥Ù„Ù‰ Ù†Ù‡Ø§ÙŠØ© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø£Ø­Ø±Ù
    text = re.sub(r"[^a-z0-9()! -]", "", text)
    return text.replace(" ", "-")

def get_episode_links():
    print("ğŸ“„ ØªØ­Ù…ÙŠÙ„ ØµÙØ­Ø© Ø§Ù„Ø­Ù„Ù‚Ø§Øª...")
    response = scraper.get(EPISODE_LIST_URL, headers=HEADERS)
    if response.status_code != 200:
        print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©. Ø§Ù„ÙƒÙˆØ¯: {response.status_code}")
        return []
    soup = BeautifulSoup(response.text, "html.parser")
    return [a.get("href") for a in soup.select(".episodes-card-title a") if a.get("href", "").startswith("http")]

def check_episode_on_github(anime_title):
    anime_id = to_id_format(anime_title)
    filename = anime_id + ".json"
    url = f"https://api.github.com/repos/{repo_name}/contents/{remote_folder}/{filename}"
    headers = {"Authorization": f"token {access_token}"}
    response = scraper.get(url, headers=headers)
    if response.status_code == 200:
        download_url = response.json().get("download_url")
        if download_url:
            r = scraper.get(download_url)
            if r.status_code == 200:
                try:
                    return True, r.json()
                except json.JSONDecodeError:
                    print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON Ù„Ù…Ù„Ù {filename} Ù…Ù† GitHub.")
                    return True, None # Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ù„ÙƒÙ† Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡ØªÙ‡ ÙƒÙ€ JSON ØµØ§Ù„Ø­
            else:
                print(f"âŒ ÙØ´Ù„ ØªÙ†Ø²ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ {filename} Ù…Ù† GitHub. Ø§Ù„ÙƒÙˆØ¯: {r.status_code}")
                return True, None # Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ù„ÙƒÙ† Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙ†Ø²ÙŠÙ„Ù‡
        return True, None # Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ù„ÙƒÙ† Ù„Ø§ ÙŠÙˆØ¬Ø¯ download_url
    elif response.status_code == 404:
        return False, None
    else:
        print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù Ø¹Ù„Ù‰ GitHub: {response.status_code} {response.text}")
        return False, None

def get_episode_data(episode_url):
    response = scraper.get(episode_url, headers=HEADERS)
    if response.status_code != 200:
        print(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù„Ù‚Ø© Ù…Ù† {episode_url}. Ø§Ù„ÙƒÙˆØ¯: {response.status_code}")
        return None, None, None, None
    soup = BeautifulSoup(response.text, "html.parser")
    h3 = soup.select_one("div.main-section h3")
    full_title = h3.get_text(strip=True) if h3 else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

    anime_title = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
    episode_number = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† "Ø§Ù„Ø­Ù„Ù‚Ø©" Ø¨Ø£ÙŠ Ø·Ø±ÙŠÙ‚Ø© ÙƒØªØ§Ø¨Ø© (Ø§Ù„Ø­Ù„Ù‚Ø©ØŒ Ø­Ù„Ù‚Ù‡)
    match = re.search(r"(Ø§Ù„Ø­Ù„Ù‚Ø©|Ø­Ù„Ù‚Ù‡)\s*(\d+)", full_title)
    if match:
        anime_title_parts = full_title.rsplit(match.group(0), 1)
        anime_title = anime_title_parts[0].strip()
        episode_number = match.group(2).strip()
    else:
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "Ø§Ù„Ø­Ù„Ù‚Ø©" Ø£Ùˆ "Ø­Ù„Ù‚Ù‡"ØŒ Ø§Ø¹ØªØ¨Ø± Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù‡Ùˆ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£Ù†Ù…ÙŠ
        anime_title = full_title.strip()
        # ÙŠÙ…ÙƒÙ†Ù†Ø§ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ù„Ø§Øµ Ø±Ù‚Ù… Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
        num_match = re.search(r'(\d+)$', anime_title)
        if num_match:
            episode_number = num_match.group(1)
            anime_title = anime_title.rsplit(episode_number, 1)[0].strip()
        else:
            episode_number = "1" # Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ Ø§Ù„Ø­Ù„Ù‚Ø© 1 Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù‚Ù…

    servers = []
    for a in soup.select("ul#episode-servers li a"):
        name = a.get_text(strip=True)
        data_url = a.get("data-ep-url")
        if isinstance(data_url, str):
            url = data_url.strip()
            if url.startswith("//"):
                url = "https:" + url
            servers.append({"serverName": name, "url": url})
    return anime_title, episode_number, full_title, servers

def log_missing_anime(anime_title, episode_link):
    """
    ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª Ø§Ù„ØªÙŠ Ù„Ù… ÙŠÙƒÙ† Ù„Ù‡Ø§ Ù…Ù„Ù JSON Ù…ÙˆØ¬ÙˆØ¯ ÙˆØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø­Ø¯ÙŠØ«Ù‹Ø§.
    """
    api_url = f"https://api.github.com/repos/{repo_name_log}/contents/{missing_anime_log_filename}"
    headers = {"Authorization": f"token {access_token}"}

    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ
    response = scraper.get(api_url, headers=headers)
    log_data = []
    sha = None

    if response.status_code == 200:
        sha = response.json().get("sha")
        try:
            content_decoded = base64.b64decode(response.json().get("content")).decode("utf-8")
            log_data = json.loads(content_decoded)
        except (json.JSONDecodeError, TypeError) as e:
            print(f"âš ï¸ ÙØ´Ù„ ÙÙƒ ØªØ´ÙÙŠØ± Ø£Ùˆ ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ: {e}. Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯.")
            log_data = []
    elif response.status_code == 404:
        print(f"â„¹ï¸ Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ {missing_anime_log_filename} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ù‰ GitHub. Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡.")
    else:
        print(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ù…Ù† GitHub: {response.status_code} {response.text}")
        return # Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø¬Ù„Ø¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ø¨Ø§Ù„ÙØ¹Ù„
    new_entry = {
        "anime_title": anime_title,
        "episode_link": episode_link,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
    if not any(item.get("anime_title") == anime_title and item.get("episode_link") == episode_link for item in log_data):
        log_data.append(new_entry)
        content_to_upload = json.dumps(log_data, indent=2, ensure_ascii=False)
        encoded_content = base64.b64encode(content_to_upload.encode("utf-8")).decode()

        payload = {
            "message": f"ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: Ø¥Ø¶Ø§ÙØ© {anime_title}",
            "content": encoded_content,
            "branch": "main"
        }
        if sha:
            payload["sha"] = sha

        r = scraper.put(api_url, headers=headers, json=payload)
        if r.status_code in [200, 201]:
            print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ {missing_anime_log_filename} Ø¹Ù„Ù‰ GitHub.")
        else:
            print(f"âŒ ÙØ´Ù„ Ø±ÙØ¹ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¥Ù„Ù‰ GitHub: {r.status_code} {r.text}")
    else:
        print(f"â„¹ï¸ Ø§Ù„Ø£Ù†Ù…ÙŠ '{anime_title}' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ù…ÙŠØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©. ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ.")

def update_new_json_list(new_anime_filename):
    """
    ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯.json Ø¹Ù†Ø¯ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ù„Ø£Ù†Ù…ÙŠ.
    """
    new_json_url = f"https://abdo12249.github.io/1/test1/episodes/{new_anime_filename}"
    api_url = f"https://api.github.com/repos/{repo_name}/contents/test1/Ø§Ù„Ø¬Ø¯ÙŠØ¯.json"
    headers = {"Authorization": f"token {access_token}"}

    # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ
    response = scraper.get(api_url, headers=headers)
    sha = None
    data = {"animes": []}

    if response.status_code == 200:
        sha = response.json().get("sha")
        try:
            content_decoded = base64.b64decode(response.json().get("content")).decode("utf-8")
            data = json.loads(content_decoded)
        except Exception as e:
            print(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯.json: {str(e)}. Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.")
            # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ù†Ø¨Ø¯Ø£ Ø¨Ø¨ÙŠØ§Ù†Ø§Øª ÙØ§Ø±ØºØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            data = {"animes": []}
        
    elif response.status_code == 404:
        print("ğŸ“ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯.json Ø¬Ø¯ÙŠØ¯.")
    else:
        print(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯.json Ù…Ù† GitHub: {response.status_code} {response.text}")
        return # Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø¬Ù„Ø¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„

    # ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
    if new_json_url not in data["animes"]:
        data["animes"].append(new_json_url)
        content_to_upload = json.dumps(data, indent=2, ensure_ascii=False)
        encoded_content = base64.b64encode(content_to_upload.encode("utf-8")).decode()

        payload = {
            "message": f"ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯.json Ø¨Ø¥Ø¶Ø§ÙØ© {new_anime_filename}",
            "content": encoded_content,
            "branch": "main"
        }
        if sha:
            payload["sha"] = sha

        r = scraper.put(api_url, headers=headers, json=payload)
        if r.status_code in [200, 201]:
            print("ğŸ“„ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯.json âœ…")
        else:
            print(f"âŒ ÙØ´Ù„ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯.json: {r.status_code} {r.text}")
    else:
        print("â„¹ï¸ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯.jsonØŒ ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ.")


def save_to_json(anime_title, episode_number, full_title, servers):
    anime_id = to_id_format(anime_title)
    filename = anime_id + ".json"
    api_url = f"https://api.github.com/repos/{repo_name}/contents/{remote_folder}/{filename}"
    headers = {"Authorization": f"token {access_token}"}
    exists_on_github, github_data = check_episode_on_github(anime_title)

    # Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ù†Ø§: Ø§Ø³ØªØ®Ø¯Ø§Ù… "Ø§Ù„Ø­Ù„Ù‚Ø© " + episode_number ÙƒØ¹Ù†ÙˆØ§Ù†
    ep_data = {
        "number": int(episode_number) if str(episode_number).isdigit() else episode_number,
        "title": f"Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number}", # ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„ÙŠØ¸Ù‡Ø± "Ø§Ù„Ø­Ù„Ù‚Ø© X" ÙÙ‚Ø·
        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "link": f"https://abdo12249.github.io/1/test1/Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ù‡.html?id={anime_id}&episode={episode_number}",
        "image": f"https://abdo12249.github.io/1/images/{anime_id}.webp", # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØµÙˆØ±Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³Ù… Ø£Ùˆ Ù‚Ù… Ø¨ØªØºÙŠÙŠØ± Ø§Ù„Ù…Ø³Ø§Ø±
        "servers": servers
    }

    if not exists_on_github:
        print(f"ğŸš€ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø£Ù†Ù…ÙŠ: {filename}")
        new_data = {
            "animeTitle": anime_title,
            "episodes": [ep_data]
        }
        content = json.dumps(new_data, indent=2, ensure_ascii=False)
        encoded = base64.b64encode(content.encode("utf-8")).decode()
        payload = {
            "message": f"Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù {filename} Ù…Ø¹ Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number}",
            "content": encoded,
            "branch": "main"
        }
        r = scraper.put(api_url, headers=headers, json=payload)
        if r.status_code in [200, 201]:
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù ÙˆØ±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ GitHub.")
            send_discord_notification(anime_title, episode_number, ep_data["link"], ep_data["image"])
            log_missing_anime(anime_title, ep_data["link"])
            update_new_json_list(filename)
        else:
            print(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ø¹Ù„Ù‰ GitHub: {r.status_code} {r.text}")
        return

    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ ÙˆÙ„ÙƒÙ† Ø¨ÙŠØ§Ù†Ø§ØªÙ‡ ÙØ§Ø±ØºØ© Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­Ø©ØŒ Ù†Ø¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯
    if github_data is None or not isinstance(github_data, dict) or "episodes" not in github_data:
        print(f"âš ï¸ Ù…Ù„Ù {filename} Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ù‰ GitHub ÙˆÙ„ÙƒÙ† Ø¨ÙŠØ§Ù†Ø§ØªÙ‡ ØºÙŠØ± ØµØ§Ù„Ø­Ø©. Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦ØªÙ‡.")
        github_data = {
            "animeTitle": anime_title,
            "episodes": [ep_data]
        }
        updated = True
        send_discord_notification(anime_title, episode_number, ep_data["link"], ep_data["image"])
    else:
        updated = False
        episode_found = False

        for i, ep in enumerate(github_data["episodes"]):
            if str(ep.get("number")) == str(ep_data["number"]):
                episode_found = True
                # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª Ø£Ùˆ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù‚Ø¯ ØªØºÙŠØ±
                # Ù‡Ù†Ø§ ÙŠØ¬Ø¨ Ø£Ù† Ù†ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø£ÙŠØ¶Ø§Ù‹ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯ "Ø§Ù„Ø­Ù„Ù‚Ø© X"
                expected_title_in_json = f"Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number}"
                if ep["servers"] != ep_data["servers"] or ep.get("title") != expected_title_in_json:
                    github_data["episodes"][i] = ep_data
                    updated = True
                    print(f"ğŸ”„ ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number} Ù„Ø£Ù† Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª Ø£Ùˆ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ØªØºÙŠØ±.")
                    send_discord_notification(anime_title, episode_number, ep_data["link"], ep_data["image"])
                else:
                    print(f"âš ï¸ Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number} Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ØªÙ… ØªØ®Ø·ÙŠÙ‡Ø§.")
                break # Ø¨Ù…Ø§ Ø£Ù†Ù†Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø§Ù„Ø­Ù„Ù‚Ø©ØŒ Ù†Ø®Ø±Ø¬ Ù…Ù† Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙˆÙ†ÙƒÙ…Ù„ Ù„Ø±ÙØ¹ Ø§Ù„ØªØ­Ø¯ÙŠØ« (Ø¥Ø°Ø§ ÙˆØ¬Ø¯)
        
        if not episode_found:
            github_data["episodes"].append(ep_data)
            updated = True
            print(f"â• ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number} Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.")
            send_discord_notification(anime_title, episode_number, ep_data["link"], ep_data["image"])
    
    if updated:
        # ØªØ£ÙƒØ¯ Ù…Ù† ØªØ±ØªÙŠØ¨ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø£Ùˆ Ø§Ù„ØªØ­Ø¯ÙŠØ«
        # Ù‡Ø°Ø§ ÙŠØ¶Ù…Ù† Ø£Ù† Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ù…Ø±ØªØ¨Ø© Ø±Ù‚Ù…ÙŠÙ‹Ø§ ÙÙŠ Ù…Ù„Ù JSON
        github_data["episodes"].sort(key=lambda x: int(x["number"]) if str(x["number"]).isdigit() else float('inf'))

        content = json.dumps(github_data, indent=2, ensure_ascii=False)
        encoded = base64.b64encode(content.encode("utf-8")).decode()

        # Ø¬Ù„Ø¨ SHA Ø§Ù„Ø£Ø®ÙŠØ± Ù‚Ø¨Ù„ Ø§Ù„Ø±ÙØ¹ Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ Ø§Ù„ØªØ¶Ø§Ø±Ø¨
        sha_response = scraper.get(api_url, headers=headers)
        sha = sha_response.json().get("sha") if sha_response.status_code == 200 else None

        payload = {
            "message": f"ØªØ­Ø¯ÙŠØ« {filename} - Ø¥Ø¶Ø§ÙØ©/ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ù„Ù‚Ø© {episode_number}",
            "content": encoded,
            "branch": "main"
        }
        if sha:
            payload["sha"] = sha

        r = scraper.put(api_url, headers=headers, json=payload)
        if r.status_code in [200, 201]:
            print(f"ğŸš€ ØªÙ… Ø±ÙØ¹ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ù„Ù‰ GitHub Ø¨Ù†Ø¬Ø§Ø­.")
        else:
            print(f"âŒ ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ù„Ù‰ GitHub: {r.status_code} {r.text}")


# Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
def main():
    print("Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ÙØ­Øµ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©...")
    all_links = get_episode_links()
    
    if not all_links:
        print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø· Ø­Ù„Ù‚Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§. Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
        return

    for idx, link in enumerate(all_links):
        print(f"\n--- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù„Ù‚Ø© {idx+1}/{len(all_links)} ---")
        anime_name, episode_number, full_title, server_list = get_episode_data(link)
        
        if anime_name and episode_number and server_list:
            save_to_json(anime_name, episode_number, full_title, server_list)
        else:
            print(f"âŒ ØªØ®Ø·ÙŠØª Ø§Ù„Ø­Ù„Ù‚Ø© {link} Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        time.sleep(1) # ØªØ£Ø®ÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø­Ø¸Ø± IP Ø£Ùˆ ØªØ¬Ø§ÙˆØ² Ø­Ø¯ÙˆØ¯ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª

    print("\nâœ… Ø§Ù†ØªÙ‡Øª Ø¹Ù…Ù„ÙŠØ© ÙØ­Øµ Ø§Ù„Ø­Ù„Ù‚Ø§Øª.")

if __name__ == "__main__":
    main()
